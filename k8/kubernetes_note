kuberneters:


Installation using Self host:

-create EC2 machine - min requirement is 2CPU and 2gb RAM

-install docker on all machines  
(use to run container )
#!/bin/bash
sudo apt update -y
curl -fsSL https://get.docker.com -o install-docker.sh
sh install-docker.sh
sudo usermod -aG docker ubuntu



-installing cri-dockerd on all nodes (Link :https://mirantis.github.io/cri-dockerd/usage/install/)
(Use of cri-dockerd- this will allow docker to be used as container runtime in kubernetes)
cd /tmp
wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.16/cri-dockerd_0.3.16.3-0.ubuntu-jammy_amd64.deb
sudo dpkg -i cri-dockerd_0.3.16.3-0.ubuntu-jammy_amd64.deb



-install kubeadm, kubectl on all nodes
(Link: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
(Use of kubeadm: used to setup k8s control plane , which includes API server, schedular, controller manager and gives join command to connect worker nodes
kubectl is used to interact with k8s API server , can perform cli operation to check cluster status, view pods , etc)

sudo apt-get update -y
# apt-transport-https may be a dummy package; if so, you can skip that package
sudo apt-get install -y apt-transport-https ca-certificates curl gpg
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
sudo systemctl enable --now kubelet


-Run below command as root user on master node:
kubeadm init --pod-network-cidr=10.244.0.0/16 --cri-socket "unix:///var/run/cri-dockerd.sock"
(here kubeadm init : initialize k8s control plane and sets up all necessary components like API server, controller manager and schedular
--pod-network : defines IP address range, ensure all pods communicate with each other 
cri-socket: tell which container runtime to use)

-To start using your cluster,  configure kubectl on master node ,you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

-run join command on worker nodes: 
kubeadm join 172.31.28.174:6443 --token y97qec.hxxc1ukgbrqeiqry \
        --discovery-token-ca-cert-hash sha256:8f3082471667d8a3264a4d3a560523b44e9d03100de475b65da6f76ba5ac373d --cri-socket "unix:///var/run/cri-dockerd.sock"


-To install flannel CNI plugins on master nodes
(Link: https://gist.github.com/rkaramandi/44c7cea91501e735ea99e356e9ae7883)

kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml




To setup autocompletion : source <(kubectl completion bash)


if flannel not working then do below:
curl -LO https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
ls -lh calico.yaml
kubectl apply -f calico.yaml


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++

k8 - 
==>Is a open source system for automating deployment, scaling and management of container application

==>Alternatives for k8 : 
-docker swarm
-apache mesos
-aws ECS

==>Kubernetes creates a cluster which is combination of multiple nodes categorized as
Worker node (node): Here the application workloads are executed
Master Node: They manage the cluster 


==>Ways to setup Kubernetes-->
Single System (Developer): This is workstation environment for developmental purposes, Here we have following major options
-minikube
-kind


Self Hosted:
-kubeadm
-kubespray (install k8s using ansible )

Cloud Hosted:
-AWS: Elastic Kubernetes Services (EKS)
-Azure: Azure Kubernetes Services (AKS)
-GCP: Google Kubernetes Engine (GKE)



==>Pod
This is the smallest unit of creation by k8s
A Pod has one or more containers in it
Every Pod gets a unique ipaddress

==>crashlookback ===> container is in exited state and k8s keeps restarting it
==>overriding entrypoint ==>use command
==>overriding cmd ==> use args   
==>if you have multiple container , if you want to access any container in pod by default it will choose main CAR i.e first container written in YAML menifest
So to choose container use -c <container name>
==>env should be passed while creating container
==>Labels we can pass after creating containers 
==>We can create multiple container in one pod for one application
e.g we can not run spring-petclinic, nop-commerce in same pod

==>service is an object which will forward the request to Pods which has matching the labels
creates virtual ip address and DNS which is fixed 
To make service accessible , the kub-proxy will do 

==>Note: Exposing Pod directly to external world is not a recommended practice

==>Generally while creating containers it is a good idea to define the cpu and memory limits

==>types of service port:
-ClusterIP---> This is the default service type. It provides a single IP address that is only accessible within the Kubernetes cluster2. It's useful for internal communication between services
-NodePort --> This type exposes a service on a static port on each node's IP address. It allows external access to the service by using the node's IP and the designated port2. This is useful for testing and development purpose
-ExternalName --> This type maps the service to an external name (DNS) instead of an IP address. It's useful for accessing services outside the cluster without exposing a specific port
-LoadBalancer -->This type provisions an external load balancer (if supported by the cloud provider) and assigns a publicly accessible IP address to the service. It's ideal for production environments where you need to expose your service to the internet




===>Deployment : which creates replica set , replicasets create pods which in turn runs the containers
Deployments are suitable for stateless applications
These come with two strategies
-Recreate
-RollingUpdated (default):
In Rolling updates
We can rollout New versions
undo rollout (rollbacks)
MaxSurge: The maximum number of pods that can be scheduled above the desired number of pods. (value can be num/percentage)
maxUnavailable	The maximum number of pods that can be unavailable during the update(value can be num/percentage)



Annotation: are like labels but we can use them for query
are used to modifying objects

When to Use kubectl rollout pause  : Scenarios

1. Staging Changes for Review
Scenario: You have multiple changes ready to be deployed but want to review them collectively before they go live.
Benefit: Pausing the rollout allows you to inspect the current state of the application and ensure that everything is in order before proceeding with the deployment.
2. Mitigating Issues During Deployment
Scenario: You notice unexpected behavior or errors during a deployment.
Benefit: By pausing the rollout, you can halt the process, investigate the issue, and make necessary adjustments without further complicating the situation.
3. Coordinating with Other Teams
Scenario: Your deployment is part of a larger release that involves multiple teams or services.
Benefit: Pausing allows you to synchronize with other teams, ensuring that all components are ready and compatible before proceeding.
4. Testing New Features
Scenario: You want to test a new feature in a controlled manner without affecting users immediately.
Benefit: Pausing the rollout gives you time to conduct thorough testing and validation before making the feature available to all users.
5. Rolling Back Changes
Scenario: You need to roll back to a previous version due to issues with the latest deployment.
Benefit: Pausing allows you to revert changes safely without introducing additional errors during the rollback process.
6. Managing Resource Constraints
Scenario: Your cluster is under heavy load, and you want to prevent further resource consumption while addressing performance issues.
Benefit: Pausing rollouts can help manage resource utilization effectively, allowing you time to resolve underlying issues.


command to delete rollout version for a deployment:
kubectl delete deployment <deployment name>
+++++++++++++++++++


Managed clusters:
Cloud providers manage the control plane i.e. we need not install k8s and the control plane will be a black box

cloud providers:
-AKS - Azure Kubernetes service
-EKS - Amazon Elastic Kubernetes Service
-GKE - Google Kubernetes Engine 



configMaps:
-it is use to store non-confidential data in key-value pairs.
-Pods can consume ConfigMaps as environment variables, command-line arguments, or as configuration files in a volume.
-ConfigMap does not provide secrecy or encryption. If the data you want to store are confidential, use a Secret rather than a ConfigMap, or use additional (third party) tools to keep your data private.
-There are four different ways that you can use a ConfigMap to configure a container inside a Pod:

	1.Inside a container command and args
	2.Environment variables for a container
	3.Add a file in read-only volume, for the application to read
	4.Write code to run inside the Pod that uses the Kubernetes API to read a ConfigMap
-immutable: If set to true, ensures that data stored in the ConfigMap cannot be updated (only object metadata can be modified). If not set to true, the field can be modified at any time. Defaulted to nil.

Secrets:
-A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key.
-Secrets are similar to ConfigMaps but are specifically intended to hold confidential data.
-Kubernetes Secrets are, by default, stored unencrypted in the API server's underlying data store (etcd). 
  hence the one which has access to API server or access to create pod in namespace can access/modify secret key
-In order to safely use Secrets, take at least the following steps:

	1.Enable Encryption at Rest for Secrets.
	2.Enable or configure RBAC rules with least-privilege access to Secrets.
        3.Restrict Secret access to specific containers.
	4.Consider using external Secret store providers.

config maps and secret:
-envfrom ===> use when want to load all config
-valuefrom ===> use when want to load specific from config

-the production approach for storing sensitive information will be:
	1.Use an external secrets manager like azure key vault, aws secrets manager, gcp secrets manager or hashicorp vault
	2.Use secrets CSI Driver of a vendor to get the sensitive information into k8s as storage


Health Checks or Probes in  Kubernetes:
In K8s we have 3 types of Probes, as per requirement you can use any of them or all:
-Liveness Probe:
Determines if the container is running or not
If Probe fails the container is restarted
-Readiness Probe:
Determines if the application is running or not
If probe fails, this container will not recieve requests from service
-Startup Probe:
Determines if the container starup is complete or not
If this probe fails no further probes are executed



Daemonsets: 
-Daemonsets are used to run a pod on each node or selected nodes
-They are useful for running agent like  software's in container
-Daemonset support rolling updates like deployments